{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELECTOR Readme\n",
    "\n",
    "SELECTOR is a library that allows to select best performing features and algorithms for human mobility prediction.\n",
    "It is composed of several scripts that all correspond to a set of steps towards deriving individual and population models.\n",
    "This readme gives an overview of these scripts, SELECTOR's functionality, and how it can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the steps\n",
    "1. Feature selection 'STEP1_feature_selection.py'.\n",
    "2. Performance assessment 'STEP2_create_candidate_individual_models.py'.\n",
    "    1. Print context feature analysis results 'STEP2a_print_candidate_individual_models_performance.py'.\n",
    "3. Create candidate individual models 'STEP3_create_feature_ranks.py'.\n",
    "    1. Create feature rank plot 'STEP3a_visualize_feature_ranks.py'.\n",
    "4. Create candidate population models 'STEP4_create_candidate_population_models.py'.\n",
    "5. Compare candidate population models to individual models 'STEP5_compare_population_models.py'.\n",
    "    1. Visualize population model performance 'STEP5a_visualize_population_model_performance.py'.\n",
    "    2. Visualize performance comparison between individual and population models 'STEP5b_visualize_individual_vs_population_model_performance.py'.\n",
    "6. Visualize performance gains of deriving population models for demographic groups 'STEP6_visualize_demographic_population_models_performance.py'.\n",
    "7. Computing and visualizing population models for day periods of time 'STEP7_visualize_demo_daily_population_models_performance.py'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important practical notes\n",
    "- Parallel execution: Although each of the main files of SELECTOR provides an option to execute it in parallel, it is however recommended to parallelize the execution as follows. Each main file provides the option to restrict the execution to a subset of users of prediction task. By simply running the same script in parallel provides a better solution for parallelizing the code. The following snippet demonstrates how parallel processes can be started for non-overlapping subsets of users. \n",
    "- Visualization: Each visualization script offers flags 'SAVE' and 'SHOW' at the top of the file. If a plot should be shown on a screen then set 'SHOW' to 'True'. To save the plot to a file, set 'SAVE' to 'True'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "screen -d -m -S run01 sh -c 'python STEP4_create_candidate_population_models.py 1 3 0 8; exec bash'\n",
    "screen -d -m -S run2 sh -c 'python STEP4_create_candidate_population_models.py 1 3 8 16; exec bash'\n",
    "screen -d -m -S run3 sh -c 'python STEP4_create_candidate_population_models.py 1 3 16 24; exec bash'\n",
    "screen -d -m -S run4 sh -c 'python STEP4_create_candidate_population_models.py 1 3 24 32; exec bash'\n",
    "screen -d -m -S run5 sh -c 'python STEP4_create_candidate_population_models.py 1 3 32 40; exec bash'\n",
    "screen -d -m -S run6 sh -c 'python STEP4_create_candidate_population_models.py 1 3 40 48; exec bash'\n",
    "screen -d -m -S run7 sh -c 'python STEP4_create_candidate_population_models.py 1 3 48 56; exec bash'\n",
    "screen -d -m -S run8 sh -c 'python STEP4_create_candidate_population_models.py 1 3 56 64; exec bash'\n",
    "screen -d -m -S run9 sh -c 'python STEP4_create_candidate_population_models.py 1 3 64 72; exec bash'\n",
    "screen -d -m -S run10 sh -c 'python STEP4_create_candidate_population_models.py 1 3 72 80; exec bash'\n",
    "screen -d -m -S run11 sh -c 'python STEP4_create_candidate_population_models.py 1 3 80 88; exec bash'\n",
    "screen -d -m -S run12 sh -c 'python STEP4_create_candidate_population_models.py 1 3 88 96; exec bash'\n",
    "screen -d -m -S run13 sh -c 'python STEP4_create_candidate_population_models.py 1 3 96 104; exec bash'\n",
    "screen -d -m -S run14 sh -c 'python STEP4_create_candidate_population_models.py 1 3 104 112; exec bash'\n",
    "screen -d -m -S run15 sh -c 'python STEP4_create_candidate_population_models.py 1 3 112 120; exec bash'\n",
    "screen -d -m -S run16 sh -c 'python STEP4_create_candidate_population_models.py 1 3 120 128; exec bash'\n",
    "screen -d -m -S run17 sh -c 'python STEP4_create_candidate_population_models.py 1 3 128 136; exec bash'\n",
    "screen -d -m -S run18 sh -c 'python STEP4_create_candidate_population_models.py 1 3 136 1000; exec bash'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script spawns 18 processes that will run on at least 18 cores (if available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Feature selection\n",
    "\n",
    "- Main file: STEP1_feature_selection.py\n",
    "- Parameters (all mandatory): \n",
    "    - start task index\n",
    "    - end task index\n",
    "    - start user index\n",
    "    - end user index\n",
    "- Example: 'python STEP1_feature_selection.py 1 3 0 1'\n",
    "\n",
    "Feature selection is the main entry point of SELECTOR.\n",
    "The core logic is summarized in the file 'STEP1_feature_selection.py'.\n",
    "By executing this file, the feature selection will be performed.\n",
    "To do so, a set of parameters need to be set as well as access to the data should be given.\n",
    "The following subsection summarize these parameters and explain how to set them and the purpose of a set of further files.\n",
    "\n",
    "### Database access\n",
    "SELECTOR requires access to a database that contains data instances along with the corresponding features.\n",
    "It is important to mention that the current SELECTOR version requires a predefined database scheme since particular columns (features) are accessed by indices instead of names.\n",
    "For each prediction task, there are two database tables containing such information.\n",
    "These tables are '!TASK!_Pre_Selected_Features' and '!TASK!_Feature_Matrix'.\n",
    "The former table contains a mask for each timestamp indicating which features and instances should be used based on their availability.\n",
    "The latter table contains the actual feature matrix for each user.\n",
    "\n",
    "The gateway to access the database is the python class 'Database_Handler.py'.\n",
    "The method 'Get_DB_Handler()' returns a database handler and allows setting database parameters such as 'username' or 'password'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Get_DB_Handler():\n",
    "    \n",
    "    return Database_Handler.Database_Handler(\"ADDRESS\", 3306, \"USERNAME\", \"PASSWORD\", \"DBNAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class further proves a set of methods to access and manipulate database tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert(self, table_name, fields, values):\n",
    "    \n",
    "def insertMany(self, table_name, fields, values):\n",
    "    \n",
    "def select(self, query):\n",
    "    \n",
    "def update(self, query):\n",
    "\n",
    "def dropTable(self, table_name):\n",
    "    \n",
    "def createTable(self, table_name, selectString):\n",
    "    \n",
    "def deleteData(self, query):\n",
    "    \n",
    "def truncateTable(self, table_name):\n",
    "    \n",
    "def getGreatestIndex(self, table_name,device_id):\n",
    "    \n",
    "def getGreatestTimestamp(self, table_name,device_id):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how to interact with the database is given in the 'STEP1_feature_selection.py' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Database_Handler\n",
    "def Save_End_Evaluation_Run_To_DB(evaluation_run):\n",
    "    \n",
    "    # store prediction run details\n",
    "    timestamp = datetime.datetime.now().strftime('%d-%m-%Y-%H:%M:%S')\n",
    "    \n",
    "    dbHandler = Database_Handler.Get_DB_Handler()\n",
    "    query = \"UPDATE %s_Prediction_Run SET end_timestamp = '%s' WHERE id = %i\" % (evaluation_run.task, timestamp, evaluation_run.run_id)\n",
    "    dbHandler.update(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving user data from the database\n",
    "\n",
    "After establishing a connection to our database, we now look at how particular user data can be retrieved.\n",
    "To do so, two data structures ('UserData.py' and 'UserDataSet.py') and a helper class ('UserDataAssemble.py') are used.\n",
    "As the first step, we initialize a 'UserData.py' object to store all user related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STEP1_feature_selection.py\n",
    "def Run_Main_Loop():\n",
    "\n",
    "    ## ...\n",
    "    \n",
    "    userData = UserData.UserData()\n",
    "    userData.userId = int(user) \n",
    "    \n",
    "    ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'UserData.py' data structure allows us to store information such as user ID, optimization set, training set, and test set of user data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from UserDataSet import UserDataSet\n",
    "\n",
    "class UserData:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.userId = None;\n",
    "        self.pre_feature_combination = None;\n",
    "        self.complete_feature_matrix = None;\n",
    "        \n",
    "        self.optimization_set = None;   \n",
    "        self.training_set = None;\n",
    "        self.test_set = None;   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have initialized the 'UserData.py' structure for our user, the next step is to load data from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## STEP1_feature_selection.py\n",
    "def Run_Main_Loop():\n",
    "\n",
    "    ## ...\n",
    "    \n",
    "    user_data_assemble = UserDataAssemble.UserDataAssemble(evaluation_run)\n",
    "    evaluation_run = user_data_assemble.Get_User_Data() \n",
    "    \n",
    "    ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sample introduces two further files.\n",
    "The file 'UserDataAssemble.py' contains all the logic to load data from the database and to parse it into three (optimization, training, test) subsets.\n",
    "Our code checks for a existing partition of data in the database.\n",
    "If it is available, the data loaded from the database are partitioned accordingly.\n",
    "Otherwise a new partition is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserDataAssemble:\n",
    "    ## ...\n",
    "    def Get_User_Data(self): \n",
    "        ## ...  \n",
    "        if evaluation_run.task == EvaluationRun.task_next_place_daily:\n",
    "            task = evaluation_run.task[5:]\n",
    "        else:\n",
    "            task = evaluation_run.task\n",
    "        query = \"SELECT optimization_array, training_array, test_array FROM %s_Prediction_Run WHERE user_id = %i  LIMIT 1\" % (task, evaluation_run.userData.userId)\n",
    "        \n",
    "        dbHandler = Database_Handler.Get_DB_Handler()\n",
    "        existing_data = dbHandler.select(query)\n",
    "        existing_data = numpy.array(existing_data)\n",
    "        \n",
    "        ## A partition exists\n",
    "        if existing_data.shape[0] > 0:\n",
    "            optimization_idx = numpy.fromstring(existing_data[0,0], sep=', ').astype(int)\n",
    "            training_idx = numpy.fromstring(existing_data[0,1], sep=', ').astype(int)\n",
    "            test_idx = numpy.fromstring(existing_data[0,2], sep=', ').astype(int)\n",
    "        else: ## No partition found --> create a new partition of data into three subsets\n",
    "            optimization_set_size = self.Get_Optimization_Set_Size(number_of_days);\n",
    "            training_set_size = self.Get_Training_Set_Size(number_of_days - optimization_set_size);\n",
    "\n",
    "            # select sub sets of data    \n",
    "            indices = numpy.random.permutation(unique_days)\n",
    "            optimization_idx, training_idx, test_idx = indices[:optimization_set_size], indices[optimization_set_size:optimization_set_size+training_set_size], indices[optimization_set_size+training_set_size:]\n",
    "\n",
    "            optimization_membership = np.array([i in optimization_idx for i in day_strings])\n",
    "            optimization_idx = numpy.where(optimization_membership == True)[0]\n",
    "\n",
    "            training_membership = np.array([i in training_idx for i in day_strings])\n",
    "            training_idx = numpy.where(training_membership == True)[0]\n",
    "\n",
    "            test_membership = np.array([i in test_idx for i in day_strings])\n",
    "            test_idx = numpy.where(test_membership == True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting partitions are then applied to the data loaded from the database to create three subsets that are encapsuled in the data structure 'UserDataSet.py'.\n",
    "This structure contains timestamps of instances, data strings, ground truth values, the corresponding feature matrix, and a mask that indicates which features should be used for the current experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserDataSet:\n",
    "    \n",
    "    def __init__ (self):\n",
    "        self.timestamps = None;\n",
    "        self.day_string = None;\n",
    "        self.time_string = None;\n",
    "        \n",
    "        self.ground_truth = None;\n",
    "        self.feature_matrix = None;\n",
    "        \n",
    "        self.rows_mask = None; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initialization of a data subset is shown in the following snippet.\n",
    "As already mentioned, SELECTOR relies on a well-defined database scheme.\n",
    "The following snippet also demonstrates this dependency, i.e., timestamps, day strings, etc. are at well-defined columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserDataAssemble:\n",
    "    ## ...\n",
    "    def Get_User_Data(self): \n",
    "        # optimization set\n",
    "        optimization_set = UserDataSet.UserDataSet()\n",
    "        optimization_set.timestamps = ravel(feature_matrix[optimization_idx, 2:3])[day_period_mask[optimization_idx]]\n",
    "        optimization_set.day_string = ravel(feature_matrix[optimization_idx, 3:4])[day_period_mask[optimization_idx]]\n",
    "        optimization_set.time_string = ravel(feature_matrix[optimization_idx, 4:5])[day_period_mask[optimization_idx]]\n",
    "        \n",
    "        optimization_set.ground_truth = (ravel(feature_matrix[optimization_idx, 7:8]).astype(float))[day_period_mask[optimization_idx]]\n",
    "        optimization_set.feature_matrix = (feature_matrix[optimization_idx, 8:feature_matrix.shape[1]])[day_period_mask[optimization_idx],:]\n",
    "        optimization_set.rows_mask = optimization_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All information regarding the current evaluation run including user data are stored in the data structure 'EvaluationRun.py'.\n",
    "Beside many parameters and fields, this data structure also provides with static fields that ensure a consistent spelling of algorithms and metrics across the entire code base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvaluationRun:\n",
    "    \n",
    "    task_next_slot_place = 'NextSlotPlace'\n",
    "    task_next_slot_transition = 'NextSlotTransition'\n",
    "    task_next_place = 'NextPlace'\n",
    "    \n",
    "    task_next_place_daily = 'DailyNextPlace'\n",
    "    \n",
    "    metric_accuracy = 'accuracy'\n",
    "    metric_fscore = 'fscore'\n",
    "    metric_MCC = 'MCC'\n",
    "    \n",
    "    alg_logistic_regression = 'logistic_regression'\n",
    "    alg_knn = 'knn'\n",
    "    alg_knn_dyn = 'knn_dyn'\n",
    "    alg_perceptron = 'perceptron'\n",
    "    alg_decision_tree = 'decision_tree'\n",
    "    alg_gradient_boost = 'gradient_boost'\n",
    "    alg_svm = 'svm'\n",
    "    alg_naivebayes = 'naive_bayes'\n",
    "    alg_stupid = 'stupid'\n",
    "    \n",
    "    ## baselines\n",
    "    alg_random = 'random'\n",
    "    alg_majority = 'majority'\n",
    "    alg_histogram = 'histogram'\n",
    "    \n",
    "    algorithms = [alg_knn_dyn, alg_naivebayes];\n",
    "    \n",
    "    metrics_next_place = [metric_accuracy, metric_fscore, metric_MCC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of how to initialize such a structure is given in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Run_Main_Loop():\n",
    "        ## ...\n",
    "        evaluation_run = EvaluationRun()\n",
    "        evaluation_run.task = current_task\n",
    "        evaluation_run.task_object = task_objects[task_id]\n",
    "\n",
    "        # feature group selection\n",
    "        evaluation_run.is_network = True;\n",
    "        evaluation_run.is_temporal = True;\n",
    "        evaluation_run.is_spatial = True;\n",
    "        evaluation_run.is_context = True;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel execution of the feature selection\n",
    "\n",
    "After getting familiar with several data structures and helper classes, we now examine the code within the file 'STEP1_feature_selection.py' and an option to execute the code in parallel.\n",
    "\n",
    "There are several alternatives to parallelize SELECTOR.\n",
    "One way is implemented in the file 'STEP1_feature_selection.py'.\n",
    "By using the flag 'THREAD_LEVEL' it allows us to create multiple threads.\n",
    "\n",
    "The lowest level to parallelize the code is to set THREAD_LEVEL = 1.\n",
    "It will allow us to run the execution for the selected performance metrics in parallel.\n",
    "The corresponding code is shown in the following snippen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Thread_Algorithm(evaluation_run, metrics, start):\n",
    "        ## ...\n",
    "        threads = []\n",
    "        for current_metric in metrics:\n",
    "            ## ... \n",
    "            if THREAD_LEVEL > 0:\n",
    "                metric_thread = threading.Thread( target=Thread_Metric, args=(current_evaluation_run, start,) )\n",
    "                threads.append(metric_thread)\n",
    "                metric_thread.start()\n",
    "            else:   \n",
    "                Thread_Metric(current_evaluation_run, start) \n",
    "\n",
    "        if THREAD_LEVEL > 0:\n",
    "            for thread in threads:\n",
    "                thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next level is to also parallize the execution of predictors.\n",
    "To do so, THREAD_LEVEL should be set to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Thread_Task(task_id, evaluation_run, algorithms, list_of_metrics, userData, start):\n",
    "        threads = []\n",
    "        for current_algorithm in algorithms:\n",
    "            ## ...\n",
    "            if THREAD_LEVEL > 1:\n",
    "                algorithm_thread = threading.Thread( target=Thread_Algorithm, args=(current_evaluation_run, metrics, start,) )\n",
    "                threads.append(algorithm_thread)\n",
    "                algorithm_thread.start()\n",
    "            else:\n",
    "                Thread_Algorithm(current_evaluation_run, metrics, start)\n",
    "\n",
    "        if THREAD_LEVEL > 1:\n",
    "            for thread in threads:\n",
    "                thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can also parallelize SELECTOR to execute for each prediction task indidually.\n",
    "To do so, we have to set THREAD_LEVEL = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Run_Main_Loop():\n",
    "        ## ...\n",
    "        threads = []\n",
    "        for current_task in tasks:\n",
    "            ## ...\n",
    "            if THREAD_LEVEL > 2:\n",
    "                task_thread = threading.Thread( target=Thread_Task, args=(task_id, evaluation_run, algorithms, list_of_metrics, userData, start,) )\n",
    "                threads.append(task_thread)\n",
    "                task_thread.start()\n",
    "            else:\n",
    "                Thread_Task(task_id, evaluation_run, algorithms, list_of_metrics, userData, start)\n",
    "            ## ...\n",
    "        if THREAD_LEVEL > 2:\n",
    "            for thread in threads:\n",
    "                thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are additional and higher values of THREAD_LEVEL that can be set to further parallelize the code.\n",
    "We will discuss these values later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kicking off the feature selection procedure\n",
    "\n",
    "After defining feature selection tasks for each combination of prediction tasks, performance metrics, users, and predictors, we now examine the code that is responsible for selecting features.\n",
    "\n",
    "This code is located in the class 'SFFS.py', which is an implementation of the Sequentual Floating Feature Selection algorithm.\n",
    "\n",
    "The following code in the file 'STEP1_feature_selection.py' starts SFFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Thread_Metric(evaluation_run, start):  \n",
    "        ## ...\n",
    "        # save data to database\n",
    "        evaluation_run = Save_Start_Evaluation_Run_To_DB(evaluation_run)  \n",
    "        \n",
    "        # prepare data\n",
    "        evaluation_run.training_set = evaluation_run.userData.optimization_set\n",
    "        evaluation_run.test_set = evaluation_run.userData.training_set\n",
    "\n",
    "        # run SFFS\n",
    "        sffs = SFFS.SFFS(evaluation_run, 10, start)\n",
    "        sffs.Run_SFFS()\n",
    "\n",
    "        Save_End_Evaluation_Run_To_DB(evaluation_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the file 'STEP1_feature_selection.py' the file 'SFFS.py' provides further options to parallelize the execution.\n",
    "This can be achieved by setting THREAD_LEVEL to 4 or higher.\n",
    "\n",
    "### Saving feature selection results to the database\n",
    "While feature selection is performed, SELECTOR stores intermediate and finale results in the database.\n",
    "There are two table per prediction task that are dedicated for this purpose.\n",
    "These tables are '!TASK!_Prediction_Result_Analysis' and '!TASK!_Prediction_Run'.\n",
    "The former table stores the results of each SFFS execution cycle, while the latter one contains high-level information of the current evaluation run, e.g., which prediction algorithm is used or which performance metric should be optimized.\n",
    "\n",
    "The file 'NextPlaceOrSlotPredictionTask.py' contains the entire code to compute the performance and store the current execution step in the database (table: '!TASK!_Prediction_Result_Analysis').\n",
    "After each SFFS step, the method 'Save_To_DB(..)' is executed.\n",
    "\n",
    "Before and after the execution of SFFS, a corresponding entry is written to the table '!TASK!_Prediction_Run' containing all the high-level information of the current evaluation run.\n",
    "The implementation of these two methods (Save_Start_Evaluation_Run_To_DB(..) and Save_End_Evaluation_Run_To_DB(..)) is in the file 'STEP1_feature_selection.py'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Create candidate individual models\n",
    "\n",
    "- Main file: STEP2_create_candidate_individual_models.py\n",
    "- Parameters (all mandatory): \n",
    "    - start task index\n",
    "    - end task index\n",
    "    - start user index\n",
    "    - end user index\n",
    "- Example: 'python STEP2_create_candidate_individual_models.py 1 3 0 1'\n",
    "\n",
    "After applying feature selection, the next step is to measure the actual performance of the predictors before and after the feature selection.\n",
    "As already mentioned, our data set is devided into three subsets.\n",
    "While the optimization and traning subsets are used by SFFS, the training and test subsets are used to assess the actual performance.\n",
    "\n",
    "Since we are also interested in the influence of phone context data on the performance in solving human mobility prediction tasks, we measure the performance in all four cases:\n",
    "- No feature selection + phone context data\n",
    "- No feature selection and no phone context data\n",
    "- After feature selection + phone context data\n",
    "- After feature selection and no phone context data\n",
    "\n",
    "The corresponding implementation of this step can be found in the file 'STEP2_create_candidate_individual_models.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP2_create_candidate_individual_models:\n",
    "    ## ...\n",
    "    BASELINE = False\n",
    "    ## ...\n",
    "    def Run_Main_Loop():\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    ## PREPARE TO RUN THE LOOP\n",
    "    list_of_metrics = [EvaluationRun.metrics_next_place, EvaluationRun.metrics_next_place, EvaluationRun.metrics_next_place]\n",
    "    algorithms = [EvaluationRun.alg_knn_dyn, EvaluationRun.alg_perceptron, EvaluationRun.alg_decision_tree, EvaluationRun.alg_svm];\n",
    "        \n",
    "    if IS_PER_DAY_PERIOD:\n",
    "        start_periods = [1, 49, 69];\n",
    "        end_periods = [48, 68, 96];\n",
    "        tasks = [EvaluationRun.task_next_place_daily]\n",
    "        task_objects = [NextPlaceOrSlotPredictionTask]\n",
    "        feature_group_combinations = [[False, True, True, True, False]];\n",
    "    else:\n",
    "        start_periods = [1];\n",
    "        end_periods = [96];\n",
    "        tasks = [EvaluationRun.task_next_slot_place, EvaluationRun.task_next_slot_transition, EvaluationRun.task_next_place]\n",
    "        task_objects = [NextPlaceOrSlotPredictionTask, NextPlaceOrSlotPredictionTask, NextPlaceOrSlotPredictionTask]\n",
    "        ## first argument: true = no feature selection; false = feature selection\n",
    "        feature_group_combinations = [[True, True, True, True, True], \n",
    "                                      [True, True, True, True, False], \n",
    "                                      [False, True, True, True, True], \n",
    "                                      [False, True, True, True, False]]; \n",
    "        \n",
    "    if BASELINE:\n",
    "        algorithms = [EvaluationRun.alg_random, EvaluationRun.alg_majority, EvaluationRun.alg_histogram];\n",
    "        feature_group_combinations = [[True, True, True, True, True]]; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows us to define which metrics and algorithms should be included.\n",
    "In the context of this evaluation, we also include three naive algorithms along with the four sophisticated.\n",
    "The flag 'BASELINE', which can be set at the top of the file, allows us to switch between sophisticated and naive predictors.\n",
    "The flag 'IS_PER_DAY_PERIOD' is set to 'True' only for building population models for different day periods of time (STEP 7). \n",
    "In default case, it is set to 'False'.\n",
    "\n",
    "The matrix 'feature_group_combinations' allows us to define the four aforementioned scenarios, while each of the five boolean values correspond to the following semantic:\n",
    "\n",
    "1. No feature selection?\n",
    "2. Network features?\n",
    "3. Temporal features?\n",
    "4. Spatial features?\n",
    "5. Phone context features?\n",
    "\n",
    "The entire structure of this file is similar to the feature selection implementation.\n",
    "The method 'Thread_Feature_Group(..)' processes all the parameters and finally performs the performance evaluation.\n",
    "\n",
    "Lastly, the results are stored in the corresponding database table 'PostSelection_!TASK!_Prediction'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2a: Print candidate individual models performance\n",
    "\n",
    "- Main file: STEP2a_print_candidate_individual_models_performance.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP2a_print_candidate_individual_models_performance.py'\n",
    "\n",
    "This script prints the performance measured in the previous step.\n",
    "The corresponding results are then printed to the console.\n",
    "The implementation of this script allows us to define for which metrics, tasks, and algorithms this information should be displayed. \n",
    "An additional flag 'IS_BASELINE' switches between the naive algorithms (for which no feature selection is applied) and the more sophisticated.\n",
    "The corresponding code snipped is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP2a_print_candidate_individual_models_performance:\n",
    "    ## ...\n",
    "    def printPerformance():\n",
    "\n",
    "        IS_BASELINE = True\n",
    "\n",
    "        list_of_metrics = [EvaluationRun.metric_accuracy, EvaluationRun.metric_fscore, EvaluationRun.metric_MCC]\n",
    "        tasks = [EvaluationRun.task_next_place, EvaluationRun.task_next_slot_place, EvaluationRun.task_next_slot_transition]\n",
    "\n",
    "        if IS_BASELINE:\n",
    "            algorithms = [EvaluationRun.alg_random, EvaluationRun.alg_histogram, EvaluationRun.alg_majority]\n",
    "            is_feature_selection_array = ['=']\n",
    "            is_phone_context_array = [1]\n",
    "        else:\n",
    "            algorithms = [EvaluationRun.alg_knn_dyn, EvaluationRun.alg_perceptron, EvaluationRun.alg_decision_tree, EvaluationRun.alg_svm]\n",
    "            is_feature_selection_array = ['=', '>']\n",
    "            is_phone_context_array = [1,0]\n",
    "\n",
    "        ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Create feature ranks\n",
    "\n",
    "- Main file: STEP3_create_feature_ranks.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP3_create_feature_ranks.py'\n",
    "\n",
    "After deriving candidate individual models, we now identify individual models (best performining out of candidates) and create a ranking of features selected in users' individual models.\n",
    "\n",
    "### Identify individual models\n",
    "The following SQL query selects an individual model for each user out of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP2_create_candidate_individual_models:\n",
    "    ## ...\n",
    "    def createFeatureRanks():\n",
    "        ## ...\n",
    "        for task in tasks:\n",
    "            for metric in list_of_metrics:\n",
    "                dbHandler = Database_Handler.Get_DB_Handler()\n",
    "                query = (\"select a.user_id, a.%s, a.selected_algorithm, a.selected_features from \"\n",
    "                         \"(select user_id, %s, selected_algorithm, selected_features from PostSelection_%s_Prediction \"\n",
    "                         \"where is_context = 0 and selected_metric = '%s' and feature_selection_id > 0 and \"\n",
    "                         \"(selected_algorithm = 'knn_dyn' or selected_algorithm = 'svm' or \"\n",
    "                         \"selected_algorithm = 'perceptron' or selected_algorithm = 'decision_tree') \"\n",
    "                         \"AND start_time = %s and end_time = %s \"\n",
    "                         \"order by %s DESC) as a group by a.user_id order by a.user_id;\"\n",
    "                         \"\") % (metric, metric, task, metric, start_periods[time_index], \n",
    "                                end_periods[time_index], metric)\n",
    "\n",
    "                query_results = numpy.array(dbHandler.select(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ranks for all demographic groups\n",
    "\n",
    "This process is repeated for all 16 demographic groups by checking for each user whether she belongs to the currently selected demographic group, as shown in the following snippen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP2_create_candidate_individual_models:\n",
    "    ## ...\n",
    "    def createFeatureRanks():\n",
    "        ## ...\n",
    "        for demo_key in get_demo_groups_dict().keys():\n",
    "\n",
    "            feature_ids = numpy.arange(0,NUMBER_OF_FEATURES,1)\n",
    "            feature_occurrence = numpy.zeros((NUMBER_OF_FEATURES,))\n",
    "            total_number_of_models = 0\n",
    "\n",
    "            # For each user\n",
    "            for row in query_results:\n",
    "                user_id = int(row[0])\n",
    "\n",
    "                # Apply the following steps only if the user belongs to the current demographic group\n",
    "                if Util.userBelongToDemoGroup(user_id, demo_key):\n",
    "                    selected_features = ravel(numpy.fromstring(row[3], sep=', ').astype(int))\n",
    "                    feature_occurrence[selected_features] += 1\n",
    "                    total_number_of_models += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the ranks for all features, we finally store the results to the database table 'FeatureRanks'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3a: Visualize feature ranks\n",
    "\n",
    "- Main file: STEP3a_visualize_feature_ranks.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP3a_visualize_feature_ranks.py'\n",
    "\n",
    "This file simply visualizes the results of the computation of feature ranks for all combinations of tasks and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../plots/feature_ranks.pdf width=550 height=275></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../plots/feature_ranks.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x104587690>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('../plots/feature_ranks.pdf',size=(550,275))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Create candidate population models\n",
    "\n",
    "- Main file: STEP4_create_candidate_population_models.py\n",
    "- Parameters (all mandatory):\n",
    "    - start task index\n",
    "    - end task index\n",
    "    - start user index\n",
    "    - end user index\n",
    "- Example: 'python STEP4_create_candidate_population_models.py 1 3 0 1'\n",
    "\n",
    "After ranking features based on the individual models, we are now able to derive candidate population models.\n",
    "The corresponding file 'STEP4_create_candidate_population_models.py' follows the same structure as previous files, therefore we mainly focus on the major differences and some of the parameters that can be set.\n",
    "\n",
    "Along the metrics, tasks, and predictors that can be selected, in this part of the evaluation we can also define how many of the top-X features should be used for the brute-force operation of deriving candidate population models or for which demographic groups it should be performed.\n",
    "\n",
    "These parameters can be set in the method 'Thread_Metric(..)' as shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP4_create_candidate_population_models:\n",
    "    ## ...\n",
    "    def Thread_Metric(evaluation_run, start):  \n",
    "        ## ...\n",
    "        feature_set_size = 5 \n",
    "    \n",
    "        for demo_group in Util.demo_groups:\n",
    "\n",
    "            ## check whether the user belongs to the demographic group\n",
    "            if Util.userBelongToDemoGroup(user, demo_group) == False:\n",
    "                continue;\n",
    "            ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file 'Util.py' contains among other useful functions also a list with all demographic groups and functions to check whether a user belongs to one of the selected groups, as shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Util:\n",
    "    ## ...\n",
    "    demo_groups = ['all', 'female','male','working','study','age_group_16_21','age_group_22_27',\n",
    "                      'age_group_28_33','age_group_34_38','age_group_39_44','no_children_all','with_children_all',\n",
    "                      'with_children_female','with_children_male','single','family'];\n",
    "\n",
    "    def areUsersBelongToDemoGroup(users, demo_group):\n",
    "\n",
    "        mask_users_belong_to_demo_group = numpy.zeros((len(users),),dtype=bool)\n",
    "\n",
    "        for idx in range(len(mask_users_belong_to_demo_group)):\n",
    "            mask_users_belong_to_demo_group[idx] = userBelongToDemoGroup(users[idx], demo_group)\n",
    "\n",
    "        return mask_users_belong_to_demo_group\n",
    "\n",
    "\n",
    "    def userBelongToDemoGroup(user, demo_group):\n",
    "\n",
    "        ## get demographic data\n",
    "        dbHandler = Database_Handler.Get_DB_Handler()\n",
    "        query = (\"select * FROM Demographics where userid = %s\") % (user) \n",
    "        demographics = numpy.array(dbHandler.select(query))\n",
    "\n",
    "        gender = demographics[0, 1]\n",
    "        age = demographics[0, 2] \n",
    "        work = demographics[0, 3]\n",
    "        relationship = demographics[0, 4]\n",
    "        children = demographics[0, 5]\n",
    "\n",
    "        if demo_group == 'all':\n",
    "            return True\n",
    "        if demo_group == 'female':\n",
    "            return gender == 1\n",
    "        if demo_group == 'male':\n",
    "            return gender == 2\n",
    "        if demo_group == 'working':\n",
    "            return work == 1\n",
    "        if demo_group == 'study':\n",
    "            return work == 4\n",
    "        if demo_group == 'age_group_16_21':\n",
    "            return age == 2\n",
    "        if demo_group == 'age_group_22_27':\n",
    "            return age == 3\n",
    "        if demo_group == 'age_group_28_33':\n",
    "            return age == 4\n",
    "        if demo_group == 'age_group_34_38':\n",
    "            return age == 5\n",
    "        if demo_group == 'age_group_39_44':\n",
    "            return age == 6\n",
    "        if demo_group == 'no_children_all':\n",
    "            return children == 0\n",
    "        if demo_group == 'with_children_all':\n",
    "            return children > 0\n",
    "        if demo_group == 'with_children_female':\n",
    "            return (children > 0) & (gender == 1)\n",
    "        if demo_group == 'with_children_male':\n",
    "            return (children > 0) & (gender == 2)\n",
    "        if demo_group == 'single':\n",
    "            return relationship == 0\n",
    "        if demo_group == 'family':\n",
    "            return relationship > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, to derive candidate population models, we apply the brute-force approach as shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP4_create_candidate_population_models:\n",
    "    ## ...\n",
    "    def Thread_Metric(evaluation_run, start):  \n",
    "        ## ...\n",
    "        dbHandler = Database_Handler.Get_DB_Handler()\n",
    "        query = (\"select feature_id FROM FeatureRanks where metric = '%s' and prediction_task = '%s' \"\n",
    "                 \"and demo_group = '%s' and daily_period = '%s' order by id\") % ( \n",
    "                 evaluation_run.selected_metric, evaluation_run.task, demo_group, daily_period)\n",
    "\n",
    "        feature_combinations = dbHandler.select(query)\n",
    "        feature_combinations = ravel(feature_combinations).astype(int);\n",
    "        feature_combinations = feature_combinations[0:feature_set_size];\n",
    "        \n",
    "        # brute-force execution\n",
    "        for L in range(1, len(feature_combinations)+1):\n",
    "            for subset in itertools.combinations(feature_combinations, L):\n",
    "\n",
    "                evaluation_run.selected_features = numpy.array(subset)\n",
    "                evaluation_run.training_set = evaluation_run.userData.training_set\n",
    "                evaluation_run.test_set = evaluation_run.userData.test_set\n",
    "                \n",
    "                # Predict mobility\n",
    "                predictors_pipeline = PredictorsPipeline(evaluation_run)\n",
    "                evaluation_run = predictors_pipeline.Run_Predictions()\n",
    "                \n",
    "                # Measure performance\n",
    "                evaluation_run.metric_results = evaluation_run.task_object.Run_Analysis(evaluation_run)\n",
    "                evaluation_run.metric_results.selected_features = evaluation_run.selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: Compare candidate population models\n",
    "\n",
    "- Main file: STEP5_compare_population_models.py\n",
    "- Parameters (all mandatory):\n",
    "    - start demographic group index\n",
    "    - end demographic group index\n",
    "- Example: 'python STEP5_compare_population_models.py 0 1'\n",
    "\n",
    "To identify best performing population models out of the candidates, we need to compare the performance results of each of the candidate to those achieved by the individual models.\n",
    "The implementation of this process can be found in the file 'STEP5_compare_population_models.py'.\n",
    "The procedure allows us to find population models for different demographic groups too.\n",
    "Therefore, along the already known parameters such as the choice of prediction tasks, we select users according to their membership in each of the demographic groups that we consider in this study.\n",
    "The following code snippet shows the initialization phase of this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP5_compare_population_models:\n",
    "    ## ...\n",
    "    def compareCandidatePopulationModels():\n",
    "        ## ...\n",
    "        list_of_metrics = [EvaluationRun.metric_accuracy, EvaluationRun.metric_fscore, EvaluationRun.metric_MCC]\n",
    "    \n",
    "        algorithms = [EvaluationRun.alg_knn_dyn, EvaluationRun.alg_perceptron, EvaluationRun.alg_decision_tree, EvaluationRun.alg_svm]; #\n",
    "\n",
    "        start_demo_group = int(sys.argv[1])\n",
    "        end_demo_group = int(sys.argv[2])\n",
    "        demo_groups = Util.demo_groups[start_demo_group:end_demo_group]\n",
    "\n",
    "        for demo_group in demo_groups:\n",
    "\n",
    "            # read user list\n",
    "            text_file = open(\"userids.txt\", \"r\")\n",
    "            user_ids = text_file.read().split('\\n')\n",
    "            text_file.close()\n",
    "\n",
    "            # Identify which users belong to the current demo group\n",
    "            mask_users_belong_to_demo_group = Util.areUsersBelongToDemoGroup(user_ids, demo_group)\n",
    "            \n",
    "            ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each prediction task and metric, our script first selects individual models of all users and then removes those users who do not belong to the current demographic group, as shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP5_compare_population_models:\n",
    "    ## ...\n",
    "    def compareCandidatePopulationModels():\n",
    "        ## ...\n",
    "        # Get individual models\n",
    "        dbHandler = Database_Handler.Get_DB_Handler()\n",
    "        query = (\"select a.%s from \"\n",
    "                 \"(select user_id, %s, selected_algorithm, selected_features from PostSelection_%s_Prediction \"\n",
    "                 \"where is_context = 0 and selected_metric = '%s' and feature_selection_id > 0 and \"\n",
    "                 \"(selected_algorithm = 'knn_dyn' or selected_algorithm = 'svm' or \"\n",
    "                 \"selected_algorithm = 'perceptron' or selected_algorithm = 'decision_tree') \"\n",
    "                 \"AND start_time = %s and end_time = %s \"\n",
    "                 \"order by %s DESC) as a group by a.user_id order by a.user_id;\"\n",
    "                 \"\") % (metric, metric, task, metric, start_periods[time_index], end_periods[time_index], metric)\n",
    "\n",
    "        query_individual_models = numpy.array(dbHandler.select(query))\n",
    "        individual_models_performance = query_individual_models[:,0]\n",
    "\n",
    "        # Remove user results that do not belong to the current demo group\n",
    "        individual_models_performance = individual_models_performance[mask_users_belong_to_demo_group]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we now select all configurations of candidate population models based on the prediction task and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP5_compare_population_models:\n",
    "    ## ...\n",
    "    def compareCandidatePopulationModels():\n",
    "        ## ...\n",
    "        # Get candidate population model configs\n",
    "        dbHandler = Database_Handler.Get_DB_Handler()\n",
    "        query = (\"select distinct(selected_features) from %s where demo_group = '%s' \"\n",
    "                 \"and prediction_task = '%s' and selected_metric = '%s' AND start_time = %s and end_time = %s;\"\n",
    "                 \"\") % (table, demo_group, task, metric, start_periods[time_index], end_periods[time_index])\n",
    "\n",
    "        query_results_selected_features = numpy.array(dbHandler.select(query))\n",
    "    \n",
    "        # Iterate over each feature subset\n",
    "        for selected_features in query_results_selected_features[:,0]:\n",
    "            number_of_features = len(ravel(numpy.fromstring(selected_features, sep=', ').astype(int)))\n",
    "            \n",
    "            # For each predictor\n",
    "            for algorithm in algorithms:\n",
    "                dbHandler = Database_Handler.Get_DB_Handler()\n",
    "                query = (\"select %s from %s where demo_group = '%s' \"\n",
    "                         \"and prediction_task = '%s' and selected_metric = '%s' and selected_algorithm = '%s' \"\n",
    "                         \"and selected_features = '%s' and start_time = %s and end_time = %s order by user_id;\"\n",
    "                         \"\") % (metric, table, demo_group, task, metric, algorithm, selected_features, \n",
    "                                start_periods[time_index], end_periods[time_index])\n",
    "\n",
    "                query_results_performance = numpy.array(dbHandler.select(query))\n",
    "                candidate_population_model_performance = query_results_performance[:,0]\n",
    "                \n",
    "                ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare the performance achieved by individual models to those achieved by each candidate population model.\n",
    "To this end, we use RMSE as the metric.\n",
    "As explained in our paper, we divide the performance results in those that indicate that individual models perform better and the rest.\n",
    "All the results are then stored in the database table 'Candidate_Population_Models_Performance'.\n",
    "The corresponding implementation is shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP5_compare_population_models:\n",
    "    ## ...\n",
    "    def compareCandidatePopulationModels():\n",
    "        ## ...\n",
    "        diff_performance = individual_models_performance - candidate_population_model_performance\n",
    "        mask_individual_model_better = diff_performance > 0\n",
    "\n",
    "        # the higher, the better is individual model\n",
    "        if sum(mask_individual_model_better) > 0:\n",
    "            RMSE_individual_models = sqrt(sum(pow(diff_performance[mask_individual_model_better], 2)) \n",
    "                                          / sum(mask_individual_model_better))\n",
    "        else:\n",
    "            RMSE_individual_models = 0.0\n",
    "        # the lower, the better is population model\n",
    "        if sum(~mask_individual_model_better) > 0:\n",
    "            RMSE_population_models = -sqrt(sum(pow(diff_performance[~mask_individual_model_better], 2)) \n",
    "                                           / sum(~mask_individual_model_better))\n",
    "        else:\n",
    "            RMSE_population_models = 0.0\n",
    "\n",
    "        RMSE_total = (RMSE_individual_models * sum(mask_individual_model_better) \n",
    "                      + RMSE_population_models * sum(~mask_individual_model_better)) \n",
    "        / len(mask_individual_model_better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5a: Visualize population model performance\n",
    "\n",
    "- Main file: STEP5a_visualize_population_model_performance.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP5a_visualize_population_model_performance.py'\n",
    "\n",
    "This script allows us to visualize the performance results achieved by the selected population models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../plots/PopulationModel_Performance_boxplot_brute_force.pdf width=750 height=250></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../plots/PopulationModel_Performance_boxplot_brute_force.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x10450f750>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('../plots/PopulationModel_Performance_boxplot_brute_force.pdf',size=(750,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5b: Visualize individual vs population model performance\n",
    "\n",
    "- Main file: STEP5b_visualize_individual_vs_population_model_performance.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP5b_visualize_individual_vs_population_model_performance.py'\n",
    "\n",
    "This script visualizes the performance differences between individual and population models when derived by considering the entire population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../plots/PopulationModel_vs_Individual_boxplot_brute_force.pdf width=750 height=250></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../plots/PopulationModel_vs_Individual_boxplot_brute_force.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x1045873d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('../plots/PopulationModel_vs_Individual_boxplot_brute_force.pdf',size=(750,250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: Performance gains of deriving population models for demographic groups\n",
    "\n",
    "- Main file: STEP6_visualize_demographic_population_models_performance.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP6_visualize_demographic_population_models_performance.py'\n",
    "\n",
    "This script retrieves performance results achieved by population models that are derived for the entire population and compares them to the results achieved if population models are derived for each demographic group separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../plots/demographic_model_improvements.pdf width=870 height=190></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../plots/demographic_model_improvements.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x10450fe10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('../plots/demographic_model_improvements.pdf',size=(870,190))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: Computing and visualizing population models for day periods of time\n",
    "\n",
    "The last part of SELECTOR introduces the possibility to derive population models for non-overlapping day periods of time.\n",
    "The current implementation considered three day periods (indicated as indexes of 15-minutes time slots starting from 00:00):\n",
    "\n",
    "- 1 - 48\n",
    "- 49 - 68\n",
    "- 69 - 96\n",
    "\n",
    "This separation is done based on analysis insights that are outside of the focus of SELECTOR.\n",
    "Nevertheless, the day periods can be easily changed as shown in the following snippet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_periods = [1, 49, 69];\n",
    "end_periods = [48, 68, 96];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct population models for different day periods of time and to finally compare their performance for population models that are constructed for the entire day, we simply need to rerun all the above mentioned six steps by changing some of the parameters.\n",
    "The following snippets along with explanations provide an overview of how to conduct such experiments with SELECTOR and which parameters in which files need to be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database and prediction task\n",
    "\n",
    "The current implementation of SELECTOR supports the construction of population models for different day periods of time for the next-place (NP) prediction task only.\n",
    "However, the implementation can be easily extended if further prediction tasks should be supported too.\n",
    "Furthermore, although all the results can be saved in the same database scheme, we decided to stored all the results in separate database tables.\n",
    "This is mainly done for debugging reasons.\n",
    "\n",
    "The corresponding tables are:\n",
    "- STEP 1:\n",
    "    - Input: NextPlace_Feature_Matrix, NextPlace_Pre_Selected_Features\n",
    "    - Output: Daily_NextPlace_Prediction_Result_Analysis, Daily_NextPlace_Prediction_Run\n",
    "- STEP 2:\n",
    "    - Input: Daily_NextPlace_Prediction_Result_Analysis, Daily_NextPlace_Prediction_Run\n",
    "    - Output: PostSelection_DailyNextPlace_Prediction\n",
    "- STEP 3:\n",
    "    - Input: PostSelection_DailyNextPlace_Prediction\n",
    "    - Output: FeatureRanksDaily\n",
    "- STEP 4:\n",
    "    - Input: FeatureRanksDaily\n",
    "    - Output: Candidate_Population_Models_Daily\n",
    "- STEP 5:\n",
    "    - Input: Candidate_Population_Models_Daily\n",
    "    - Output: Candidate_Population_Models_Performance_Daily\n",
    "- STEP 6: [THIS STEP IS OMITTED AND REPLACED BY STEP 7]\n",
    "- STEP 7:\n",
    "    - Input: Candidate_Population_Models_Daily, Candidate_Population_Models_Performance_Daily\n",
    "    - Output: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1  5\n",
    "\n",
    "To repeat STEP 1 to STEP 5 in the context of building population models for different day periods of time, we simply need to change the flag 'IS_PER_DAY_PERIOD' in each of the files, as shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    IS_PER_DAY_PERIOD = True\n",
    "    ## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other parameters such as prediction tasks will be changed automatically by a if-else statement, as shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class STEP1_feature_selection:\n",
    "    ## ...\n",
    "    def Run_Main_Loop():\n",
    "\n",
    "        start = time()\n",
    "\n",
    "        ## PREPARE TO RUN THE LOOP\n",
    "        list_of_metrics = [EvaluationRun.metrics_next_place, EvaluationRun.metrics_next_place, EvaluationRun.metrics_next_place]\n",
    "        algorithms = [EvaluationRun.alg_knn_dyn, EvaluationRun.alg_perceptron, EvaluationRun.alg_decision_tree, EvaluationRun.alg_svm];\n",
    "\n",
    "        # Select a configuration depending on whether the mobility should be predicted for specific day periods of time or not\n",
    "        if IS_PER_DAY_PERIOD:\n",
    "            start_periods = [1, 49, 69];\n",
    "            end_periods = [48, 68, 96];\n",
    "            tasks = [EvaluationRun.task_next_place_daily]\n",
    "            task_objects = [NextPlaceOrSlotPredictionTask]\n",
    "        else:\n",
    "            start_periods = [1];\n",
    "            end_periods = [96];\n",
    "            tasks = [EvaluationRun.task_next_slot_place, EvaluationRun.task_next_slot_transition, EvaluationRun.task_next_place]\n",
    "            task_objects = [NextPlaceOrSlotPredictionTask, NextPlaceOrSlotPredictionTask, NextPlaceOrSlotPredictionTask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of STEPS 1  5\n",
    "\n",
    "In the context of STEP 7 analysis, all the visualization steps 2a, 3a, 5a, and 5b are skipped and replaced by the final visualization of STEP 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of performance comparison of different types of population models\n",
    "\n",
    "- Main file: STEP7_visualize_demo_daily_population_models_performance.py\n",
    "- Parameters (all mandatory): No\n",
    "- Example: 'python STEP7_visualize_demo_daily_population_models_performance.py'\n",
    "\n",
    "Lastly, we visualize the performance differences between population models that are built for different day periods of time and those built for the entire day.\n",
    "Along comparing for the entire population of users, we also compare for each of the 15 demographic groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../plots/daily_vs_all_population_model_improvements.pdf width=870 height=210></iframe>"
      ],
      "text/latex": [
       "\\includegraphics[width=1.0\\textwidth]{../plots/daily_vs_all_population_model_improvements.pdf}"
      ],
      "text/plain": [
       "<__main__.PDF at 0x10450fd10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDF('../plots/daily_vs_all_population_model_improvements.pdf',size=(870,210))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PDF(object):\n",
    "  def __init__(self, pdf, size=(200,200)):\n",
    "    self.pdf = pdf\n",
    "    self.size = size\n",
    "\n",
    "  def _repr_html_(self):\n",
    "    return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "  def _repr_latex_(self):\n",
    "    return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
